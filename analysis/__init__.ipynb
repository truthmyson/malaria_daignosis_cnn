{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cnnclassifier.utils.common import read_dataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from cnnclassifier.components.model_building import model_building\n",
    "from cnnclassifier.config.configuration import configManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01edd05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f25bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "config = configManager()\n",
    "m = model_building(config.get_build_model_config_params())\n",
    "model = m.build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8acd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model = m.compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e153af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train nd validte the model\n",
    "train_data = read_dataset(\"artifacts/split_data/train\")\n",
    "val_data = read_dataset(\"artifacts/split_data/validate\")\n",
    "\n",
    "from cnnclassifier.components.preprocessing import preprocessing\n",
    "p = preprocessing(config.get_preprocess_data_config_params())\n",
    "train_data = p.preprocess(train_data)\n",
    "val_data = p.preprocess(val_data)\n",
    "\n",
    "model, history = m.train_validate_model(model, train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bb414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f592e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249213fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eccf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnclassifier.utils.common import read_dataset\n",
    "dataset = read_dataset('artifacts/split_data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will plot some of the images using subplot\n",
    "for i, (image, label) in enumerate(dataset.take(25)):\n",
    "    axes = plt.subplot(5,5, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(['infected' if label == 0 else 'safe'])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will pratice resizing and normalizing\n",
    "IMG_SIZE = 244\n",
    "def resize_normalize(image,label):\n",
    "    return tf.image.resize(image,[IMG_SIZE,IMG_SIZE])/255.0, label\n",
    "\n",
    "__dataset = dataset.map(resize_normalize)\n",
    "__dataset = __dataset.shuffle(32).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# the batch will divide the total data into the batch size\n",
    "\n",
    "print(__dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b635dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for image, label in dataset:\n",
    "    if int(image.shape[0]) > 244 or int(image.shape[1]) > 244:\n",
    "        # print( int(label), image.shape)\n",
    "        # print('\\n')\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31919a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for image, label in dataset:\n",
    "    height= image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    channel = image.shape[2]\n",
    "    label = int(label)\n",
    "    max_val = int(np.max(image))\n",
    "    min_val = int(np.min(image))\n",
    "\n",
    "    data.append({\n",
    "            'height':height,\n",
    "            'width':width,\n",
    "            'channel':channel,\n",
    "            'label':label,\n",
    "            'max_val':max_val,\n",
    "            'min_val':min_val\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "daf = pd.DataFrame(data, columns=['height', 'width', 'channel','label','max_val','min_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bcd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "daf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e26103",
   "metadata": {},
   "source": [
    "EDA on the images\n",
    "1. The dtype of the images is 'uint8', which is is an 8-bit unsigned integer data type that can store values ranging from 0 to 255\n",
    "2. from our train data set, i found out that there are 13 images with either the height > than 244 or width > 244 but all the channels for the images are 3. therefore wewill resize all the images to (244,244,3)\n",
    "this can be done int the model or out side the model\n",
    "3. Because the the image's numpy array ranges between 0 to 255, therefore we will normalize it to a range of 0 to 1\n",
    "4. if the label for the imagfe is 0 that means infected but if is 1 that means safe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
